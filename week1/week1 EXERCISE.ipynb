{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a5e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a coding assistant. You will be provided with a code snippet and your task is to explain the code in detail.\\\n",
    "The code snippet will be in Python. You should provide a detailed explanation of the code. It should be in a markdown format. \\\n",
    "It might happen that the code is not correct. In that case, you should provide a detailed explanation of the code and then provide the correct code snippet.\\\n",
    "If not asked for more, anwer in up to 250 words.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57f3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt(code: str) -> str:\n",
    "    return f\"Explain the following code in detail:\\n\\n{code}\\n\\n###\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def gpt_code_assist(code):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt(code)}\n",
    "          ],\n",
    "        stream=True,\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "def llama_code_assist(code):\n",
    "    ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt(code)}\n",
    "          ],\n",
    "        stream=True,\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4753c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_assist(code, model = 'llama'):\n",
    "    \n",
    "    if model == 'gpt':\n",
    "        openai = OpenAI()\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL_GPT,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\":system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt(code)}\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "    \n",
    "    elif model == 'llama':\n",
    "        \n",
    "        ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "        stream = ollama_via_openai.chat.completions.create(\n",
    "            model=MODEL_LLAMA,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\":system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt(code)}\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Model not available. Please use 'gpt' or 'llama'.\")\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653f6a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided code snippet uses Python's `yield from` syntax along with a set comprehension. Let's break it down step by step:\n",
       "\n",
       "### Components of the Code\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   \n",
       "   - This creates a set of unique authors from a collection of `books`.\n",
       "   - It iterates over each `book` in the `books` iterable.\n",
       "   - The expression `book.get(\"author\")` retrieves the value associated with the key `\"author\"` from each `book` dictionary.\n",
       "   - The `if book.get(\"author\")` condition ensures that only authors that are present (i.e., not `None`) are included in the set, preventing empty or missing authors from being considered.\n",
       "\n",
       "2. **`yield from`**:\n",
       "   python\n",
       "   yield from ...\n",
       "   \n",
       "   - The `yield from` expression is typically used inside a generator function to yield values from an iterable one by one. \n",
       "   - In this context, it will generate each author in the set produced by the set comprehension.\n",
       "\n",
       "### Purpose of the Code\n",
       "The overall purpose of this code is to create a generator that yields each unique author's name from the provided `books` iterable, ensuring that only valid (non-None) author names are included.\n",
       "\n",
       "### Code Correction\n",
       "This code snippet is mostly correct but should ideally be wrapped in a generator function for `yield from` to work properly. Hereâ€™s how it might look:\n",
       "\n",
       "python\n",
       "def unique_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "### Summary\n",
       "This code snippet is useful for extracting unique authors from a list of book dictionaries efficiently, enabling further operations or iterations over the authors in a generator style."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_assist(question, model='gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "792c68fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_assist import code_assist as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46aff68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided code snippet uses a Python generator along with a set comprehension to yield authors from a collection of book dictionaries. Here's a detailed explanation of each component of the code:\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "### Breakdown of the Code:\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}`: This part of the code creates a set by iterating over a collection called `books`. It extracts the value of the `\"author\"` key for each `book` dictionary.\n",
       "   - The condition `if book.get(\"author\")` ensures that only authors that are not `None` or empty strings are included in the set. If a `book` does not contain a valid author, it will be excluded from the final set. Since a set only stores unique values, any duplicate authors will be stored only once.\n",
       "\n",
       "2. **Yielding from a Set**:\n",
       "   - `yield from`: This keyword allows a generator to yield multiple values from another iterable (like a set). In this case, the values being yielded are the unique authors extracted from the set comprehension.\n",
       "\n",
       "### Purpose:\n",
       "The overall purpose of this code is to create a generator that yields each unique, valid author from a list of books. This is useful in scenarios where one needs to process or display each author without duplicates, which can occur when there are multiple books by the same author in the `books` collection.\n",
       "\n",
       "### Correctness:\n",
       "The code appears correct syntactically and logically, assuming that `books` is a list or similar iterable containing dictionaries with an `\"author\"` key. If used within a generator function, it would work as intended."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ca(question, model='gpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
